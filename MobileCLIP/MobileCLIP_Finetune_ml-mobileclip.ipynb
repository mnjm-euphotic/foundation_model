{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9b6f8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! git clone https://github.com/apple/ml-mobileclip.git /home/ml-mobileclip\n",
    "# ! sed -i 's/torchvision==/torchvision>=/' /home/ml-mobileclip/requirements.txt\n",
    "# ! pip install -e /home/ml-mobileclip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e29c6799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://huggingface.co/apple/MobileCLIP-S2/resolve/main/mobileclip_s2.pt?download=true -O /home/mobileclip_s2.pt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822f112b",
   "metadata": {},
   "source": [
    "# MobileCLIP FineTuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "910eee00-d7bd-4006-aab1-06ae9bcafb6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/py3.10/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "# from torch.utils.tensorboard import SummaryWriter\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import mobileclip\n",
    "import datetime\n",
    "tensorboard = False\n",
    "if tensorboard:\n",
    "    from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2fb5e46",
   "metadata": {},
   "source": [
    "## Hyper Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c23e1f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optim\n",
    "opt_kargs = {\n",
    "    'lr' : 1e-2, # TODO: Figure out LR decay, either step decay or warm restart\n",
    "    'betas': (0.9, 0.95),\n",
    "    'weight_decay' : 0.0,\n",
    "    'eps': 1e-8,\n",
    "}\n",
    "\n",
    "num_epochs = 20\n",
    "temperature = torch.tensor(0.1, device=device) # TODO: How to finetune this?\n",
    "lit_mode = False\n",
    "batch_size = 16\n",
    "dataset_path = \"/home/onion_clean\"\n",
    "b_test = False\n",
    "\n",
    "checkpoint_path = \"/home/mobile_clip_finetuned.pth\"\n",
    "\n",
    "# best_checkpoint_file = \"mobile_clip_finetuned.pth\" # If None will not load\n",
    "best_checkpoint_file = \"/home/mobile_clip_finetuned.pth\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b178290d-d513-44a6-b17c-8f962038beed",
   "metadata": {},
   "source": [
    "## Load model and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d717fa4f-6480-4e63-9f4d-2bdee48e830f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ml-mobileclip/mobileclip/__init__.py:75: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  chkpt = torch.load(pretrained)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CLIP(\n",
       "  (image_encoder): MCi(\n",
       "    (model): FastViT(\n",
       "      (patch_embed): Sequential(\n",
       "        (0): MobileOneBlock(\n",
       "          (se): Identity()\n",
       "          (activation): GELU(approximate='none')\n",
       "          (reparam_conv): Conv2d(3, 80, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        )\n",
       "        (1): MobileOneBlock(\n",
       "          (se): Identity()\n",
       "          (activation): GELU(approximate='none')\n",
       "          (reparam_conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=80)\n",
       "        )\n",
       "        (2): MobileOneBlock(\n",
       "          (se): Identity()\n",
       "          (activation): GELU(approximate='none')\n",
       "          (reparam_conv): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (network): ModuleList(\n",
       "        (0): Sequential(\n",
       "          (0): RepMixerBlock(\n",
       "            (token_mixer): RepMixer(\n",
       "              (reparam_conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80)\n",
       "            )\n",
       "            (convffn): ConvFFN(\n",
       "              (conv): Sequential(\n",
       "                (conv): Conv2d(80, 80, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=80, bias=False)\n",
       "                (bn): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "              (fc1): Conv2d(80, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act): GELU(approximate='none')\n",
       "              (fc2): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (1): RepMixerBlock(\n",
       "            (token_mixer): RepMixer(\n",
       "              (reparam_conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80)\n",
       "            )\n",
       "            (convffn): ConvFFN(\n",
       "              (conv): Sequential(\n",
       "                (conv): Conv2d(80, 80, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=80, bias=False)\n",
       "                (bn): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "              (fc1): Conv2d(80, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act): GELU(approximate='none')\n",
       "              (fc2): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (2): RepMixerBlock(\n",
       "            (token_mixer): RepMixer(\n",
       "              (reparam_conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80)\n",
       "            )\n",
       "            (convffn): ConvFFN(\n",
       "              (conv): Sequential(\n",
       "                (conv): Conv2d(80, 80, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=80, bias=False)\n",
       "                (bn): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "              (fc1): Conv2d(80, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act): GELU(approximate='none')\n",
       "              (fc2): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (3): RepMixerBlock(\n",
       "            (token_mixer): RepMixer(\n",
       "              (reparam_conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80)\n",
       "            )\n",
       "            (convffn): ConvFFN(\n",
       "              (conv): Sequential(\n",
       "                (conv): Conv2d(80, 80, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=80, bias=False)\n",
       "                (bn): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "              (fc1): Conv2d(80, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act): GELU(approximate='none')\n",
       "              (fc2): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "        )\n",
       "        (1): PatchEmbed(\n",
       "          (proj): Sequential(\n",
       "            (0): ReparamLargeKernelConv(\n",
       "              (activation): GELU(approximate='none')\n",
       "              (se): Identity()\n",
       "              (lkb_reparam): Conv2d(80, 160, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), groups=80)\n",
       "            )\n",
       "            (1): MobileOneBlock(\n",
       "              (se): Identity()\n",
       "              (activation): GELU(approximate='none')\n",
       "              (reparam_conv): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): Sequential(\n",
       "          (0): RepMixerBlock(\n",
       "            (token_mixer): RepMixer(\n",
       "              (reparam_conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160)\n",
       "            )\n",
       "            (convffn): ConvFFN(\n",
       "              (conv): Sequential(\n",
       "                (conv): Conv2d(160, 160, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=160, bias=False)\n",
       "                (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "              (fc1): Conv2d(160, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act): GELU(approximate='none')\n",
       "              (fc2): Conv2d(480, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (1): RepMixerBlock(\n",
       "            (token_mixer): RepMixer(\n",
       "              (reparam_conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160)\n",
       "            )\n",
       "            (convffn): ConvFFN(\n",
       "              (conv): Sequential(\n",
       "                (conv): Conv2d(160, 160, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=160, bias=False)\n",
       "                (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "              (fc1): Conv2d(160, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act): GELU(approximate='none')\n",
       "              (fc2): Conv2d(480, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (2): RepMixerBlock(\n",
       "            (token_mixer): RepMixer(\n",
       "              (reparam_conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160)\n",
       "            )\n",
       "            (convffn): ConvFFN(\n",
       "              (conv): Sequential(\n",
       "                (conv): Conv2d(160, 160, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=160, bias=False)\n",
       "                (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "              (fc1): Conv2d(160, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act): GELU(approximate='none')\n",
       "              (fc2): Conv2d(480, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (3): RepMixerBlock(\n",
       "            (token_mixer): RepMixer(\n",
       "              (reparam_conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160)\n",
       "            )\n",
       "            (convffn): ConvFFN(\n",
       "              (conv): Sequential(\n",
       "                (conv): Conv2d(160, 160, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=160, bias=False)\n",
       "                (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "              (fc1): Conv2d(160, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act): GELU(approximate='none')\n",
       "              (fc2): Conv2d(480, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (4): RepMixerBlock(\n",
       "            (token_mixer): RepMixer(\n",
       "              (reparam_conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160)\n",
       "            )\n",
       "            (convffn): ConvFFN(\n",
       "              (conv): Sequential(\n",
       "                (conv): Conv2d(160, 160, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=160, bias=False)\n",
       "                (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "              (fc1): Conv2d(160, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act): GELU(approximate='none')\n",
       "              (fc2): Conv2d(480, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (5): RepMixerBlock(\n",
       "            (token_mixer): RepMixer(\n",
       "              (reparam_conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160)\n",
       "            )\n",
       "            (convffn): ConvFFN(\n",
       "              (conv): Sequential(\n",
       "                (conv): Conv2d(160, 160, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=160, bias=False)\n",
       "                (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "              (fc1): Conv2d(160, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act): GELU(approximate='none')\n",
       "              (fc2): Conv2d(480, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (6): RepMixerBlock(\n",
       "            (token_mixer): RepMixer(\n",
       "              (reparam_conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160)\n",
       "            )\n",
       "            (convffn): ConvFFN(\n",
       "              (conv): Sequential(\n",
       "                (conv): Conv2d(160, 160, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=160, bias=False)\n",
       "                (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "              (fc1): Conv2d(160, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act): GELU(approximate='none')\n",
       "              (fc2): Conv2d(480, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (7): RepMixerBlock(\n",
       "            (token_mixer): RepMixer(\n",
       "              (reparam_conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160)\n",
       "            )\n",
       "            (convffn): ConvFFN(\n",
       "              (conv): Sequential(\n",
       "                (conv): Conv2d(160, 160, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=160, bias=False)\n",
       "                (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "              (fc1): Conv2d(160, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act): GELU(approximate='none')\n",
       "              (fc2): Conv2d(480, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (8): RepMixerBlock(\n",
       "            (token_mixer): RepMixer(\n",
       "              (reparam_conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160)\n",
       "            )\n",
       "            (convffn): ConvFFN(\n",
       "              (conv): Sequential(\n",
       "                (conv): Conv2d(160, 160, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=160, bias=False)\n",
       "                (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "              (fc1): Conv2d(160, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act): GELU(approximate='none')\n",
       "              (fc2): Conv2d(480, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (9): RepMixerBlock(\n",
       "            (token_mixer): RepMixer(\n",
       "              (reparam_conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160)\n",
       "            )\n",
       "            (convffn): ConvFFN(\n",
       "              (conv): Sequential(\n",
       "                (conv): Conv2d(160, 160, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=160, bias=False)\n",
       "                (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "              (fc1): Conv2d(160, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act): GELU(approximate='none')\n",
       "              (fc2): Conv2d(480, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (10): RepMixerBlock(\n",
       "            (token_mixer): RepMixer(\n",
       "              (reparam_conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160)\n",
       "            )\n",
       "            (convffn): ConvFFN(\n",
       "              (conv): Sequential(\n",
       "                (conv): Conv2d(160, 160, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=160, bias=False)\n",
       "                (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "              (fc1): Conv2d(160, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act): GELU(approximate='none')\n",
       "              (fc2): Conv2d(480, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (11): RepMixerBlock(\n",
       "            (token_mixer): RepMixer(\n",
       "              (reparam_conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160)\n",
       "            )\n",
       "            (convffn): ConvFFN(\n",
       "              (conv): Sequential(\n",
       "                (conv): Conv2d(160, 160, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=160, bias=False)\n",
       "                (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "              (fc1): Conv2d(160, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act): GELU(approximate='none')\n",
       "              (fc2): Conv2d(480, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "        )\n",
       "        (3): PatchEmbed(\n",
       "          (proj): Sequential(\n",
       "            (0): ReparamLargeKernelConv(\n",
       "              (activation): GELU(approximate='none')\n",
       "              (se): SEModule(\n",
       "                (fc1): Conv2d(320, 80, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (bn): Identity()\n",
       "                (act): ReLU(inplace=True)\n",
       "                (fc2): Conv2d(80, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (gate): Sigmoid()\n",
       "              )\n",
       "              (lkb_reparam): Conv2d(160, 320, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), groups=160)\n",
       "            )\n",
       "            (1): MobileOneBlock(\n",
       "              (se): Identity()\n",
       "              (activation): GELU(approximate='none')\n",
       "              (reparam_conv): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (4): Sequential(\n",
       "          (0): RepMixerBlock(\n",
       "            (token_mixer): RepMixer(\n",
       "              (reparam_conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320)\n",
       "            )\n",
       "            (convffn): ConvFFN(\n",
       "              (conv): Sequential(\n",
       "                (conv): Conv2d(320, 320, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=320, bias=False)\n",
       "                (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "              (fc1): Conv2d(320, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act): GELU(approximate='none')\n",
       "              (fc2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (1): RepMixerBlock(\n",
       "            (token_mixer): RepMixer(\n",
       "              (reparam_conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320)\n",
       "            )\n",
       "            (convffn): ConvFFN(\n",
       "              (conv): Sequential(\n",
       "                (conv): Conv2d(320, 320, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=320, bias=False)\n",
       "                (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "              (fc1): Conv2d(320, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act): GELU(approximate='none')\n",
       "              (fc2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (2): RepMixerBlock(\n",
       "            (token_mixer): RepMixer(\n",
       "              (reparam_conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320)\n",
       "            )\n",
       "            (convffn): ConvFFN(\n",
       "              (conv): Sequential(\n",
       "                (conv): Conv2d(320, 320, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=320, bias=False)\n",
       "                (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "              (fc1): Conv2d(320, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act): GELU(approximate='none')\n",
       "              (fc2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (3): RepMixerBlock(\n",
       "            (token_mixer): RepMixer(\n",
       "              (reparam_conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320)\n",
       "            )\n",
       "            (convffn): ConvFFN(\n",
       "              (conv): Sequential(\n",
       "                (conv): Conv2d(320, 320, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=320, bias=False)\n",
       "                (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "              (fc1): Conv2d(320, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act): GELU(approximate='none')\n",
       "              (fc2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (4): RepMixerBlock(\n",
       "            (token_mixer): RepMixer(\n",
       "              (reparam_conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320)\n",
       "            )\n",
       "            (convffn): ConvFFN(\n",
       "              (conv): Sequential(\n",
       "                (conv): Conv2d(320, 320, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=320, bias=False)\n",
       "                (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "              (fc1): Conv2d(320, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act): GELU(approximate='none')\n",
       "              (fc2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (5): RepMixerBlock(\n",
       "            (token_mixer): RepMixer(\n",
       "              (reparam_conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320)\n",
       "            )\n",
       "            (convffn): ConvFFN(\n",
       "              (conv): Sequential(\n",
       "                (conv): Conv2d(320, 320, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=320, bias=False)\n",
       "                (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "              (fc1): Conv2d(320, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act): GELU(approximate='none')\n",
       "              (fc2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (6): RepMixerBlock(\n",
       "            (token_mixer): RepMixer(\n",
       "              (reparam_conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320)\n",
       "            )\n",
       "            (convffn): ConvFFN(\n",
       "              (conv): Sequential(\n",
       "                (conv): Conv2d(320, 320, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=320, bias=False)\n",
       "                (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "              (fc1): Conv2d(320, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act): GELU(approximate='none')\n",
       "              (fc2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (7): RepMixerBlock(\n",
       "            (token_mixer): RepMixer(\n",
       "              (reparam_conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320)\n",
       "            )\n",
       "            (convffn): ConvFFN(\n",
       "              (conv): Sequential(\n",
       "                (conv): Conv2d(320, 320, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=320, bias=False)\n",
       "                (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "              (fc1): Conv2d(320, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act): GELU(approximate='none')\n",
       "              (fc2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (8): RepMixerBlock(\n",
       "            (token_mixer): RepMixer(\n",
       "              (reparam_conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320)\n",
       "            )\n",
       "            (convffn): ConvFFN(\n",
       "              (conv): Sequential(\n",
       "                (conv): Conv2d(320, 320, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=320, bias=False)\n",
       "                (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "              (fc1): Conv2d(320, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act): GELU(approximate='none')\n",
       "              (fc2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (9): RepMixerBlock(\n",
       "            (token_mixer): RepMixer(\n",
       "              (reparam_conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320)\n",
       "            )\n",
       "            (convffn): ConvFFN(\n",
       "              (conv): Sequential(\n",
       "                (conv): Conv2d(320, 320, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=320, bias=False)\n",
       "                (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "              (fc1): Conv2d(320, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act): GELU(approximate='none')\n",
       "              (fc2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (10): RepMixerBlock(\n",
       "            (token_mixer): RepMixer(\n",
       "              (reparam_conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320)\n",
       "            )\n",
       "            (convffn): ConvFFN(\n",
       "              (conv): Sequential(\n",
       "                (conv): Conv2d(320, 320, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=320, bias=False)\n",
       "                (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "              (fc1): Conv2d(320, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act): GELU(approximate='none')\n",
       "              (fc2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (11): RepMixerBlock(\n",
       "            (token_mixer): RepMixer(\n",
       "              (reparam_conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320)\n",
       "            )\n",
       "            (convffn): ConvFFN(\n",
       "              (conv): Sequential(\n",
       "                (conv): Conv2d(320, 320, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=320, bias=False)\n",
       "                (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "              (fc1): Conv2d(320, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act): GELU(approximate='none')\n",
       "              (fc2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (12): RepMixerBlock(\n",
       "            (token_mixer): RepMixer(\n",
       "              (reparam_conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320)\n",
       "            )\n",
       "            (convffn): ConvFFN(\n",
       "              (conv): Sequential(\n",
       "                (conv): Conv2d(320, 320, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=320, bias=False)\n",
       "                (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "              (fc1): Conv2d(320, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act): GELU(approximate='none')\n",
       "              (fc2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (13): RepMixerBlock(\n",
       "            (token_mixer): RepMixer(\n",
       "              (reparam_conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320)\n",
       "            )\n",
       "            (convffn): ConvFFN(\n",
       "              (conv): Sequential(\n",
       "                (conv): Conv2d(320, 320, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=320, bias=False)\n",
       "                (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "              (fc1): Conv2d(320, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act): GELU(approximate='none')\n",
       "              (fc2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (14): RepMixerBlock(\n",
       "            (token_mixer): RepMixer(\n",
       "              (reparam_conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320)\n",
       "            )\n",
       "            (convffn): ConvFFN(\n",
       "              (conv): Sequential(\n",
       "                (conv): Conv2d(320, 320, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=320, bias=False)\n",
       "                (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "              (fc1): Conv2d(320, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act): GELU(approximate='none')\n",
       "              (fc2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (15): RepMixerBlock(\n",
       "            (token_mixer): RepMixer(\n",
       "              (reparam_conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320)\n",
       "            )\n",
       "            (convffn): ConvFFN(\n",
       "              (conv): Sequential(\n",
       "                (conv): Conv2d(320, 320, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=320, bias=False)\n",
       "                (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "              (fc1): Conv2d(320, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act): GELU(approximate='none')\n",
       "              (fc2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (16): RepMixerBlock(\n",
       "            (token_mixer): RepMixer(\n",
       "              (reparam_conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320)\n",
       "            )\n",
       "            (convffn): ConvFFN(\n",
       "              (conv): Sequential(\n",
       "                (conv): Conv2d(320, 320, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=320, bias=False)\n",
       "                (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "              (fc1): Conv2d(320, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act): GELU(approximate='none')\n",
       "              (fc2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (17): RepMixerBlock(\n",
       "            (token_mixer): RepMixer(\n",
       "              (reparam_conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320)\n",
       "            )\n",
       "            (convffn): ConvFFN(\n",
       "              (conv): Sequential(\n",
       "                (conv): Conv2d(320, 320, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=320, bias=False)\n",
       "                (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "              (fc1): Conv2d(320, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act): GELU(approximate='none')\n",
       "              (fc2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (18): RepMixerBlock(\n",
       "            (token_mixer): RepMixer(\n",
       "              (reparam_conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320)\n",
       "            )\n",
       "            (convffn): ConvFFN(\n",
       "              (conv): Sequential(\n",
       "                (conv): Conv2d(320, 320, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=320, bias=False)\n",
       "                (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "              (fc1): Conv2d(320, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act): GELU(approximate='none')\n",
       "              (fc2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (19): RepMixerBlock(\n",
       "            (token_mixer): RepMixer(\n",
       "              (reparam_conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320)\n",
       "            )\n",
       "            (convffn): ConvFFN(\n",
       "              (conv): Sequential(\n",
       "                (conv): Conv2d(320, 320, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=320, bias=False)\n",
       "                (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "              (fc1): Conv2d(320, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act): GELU(approximate='none')\n",
       "              (fc2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (20): RepMixerBlock(\n",
       "            (token_mixer): RepMixer(\n",
       "              (reparam_conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320)\n",
       "            )\n",
       "            (convffn): ConvFFN(\n",
       "              (conv): Sequential(\n",
       "                (conv): Conv2d(320, 320, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=320, bias=False)\n",
       "                (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "              (fc1): Conv2d(320, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act): GELU(approximate='none')\n",
       "              (fc2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (21): RepMixerBlock(\n",
       "            (token_mixer): RepMixer(\n",
       "              (reparam_conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320)\n",
       "            )\n",
       "            (convffn): ConvFFN(\n",
       "              (conv): Sequential(\n",
       "                (conv): Conv2d(320, 320, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=320, bias=False)\n",
       "                (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "              (fc1): Conv2d(320, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act): GELU(approximate='none')\n",
       "              (fc2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (22): RepMixerBlock(\n",
       "            (token_mixer): RepMixer(\n",
       "              (reparam_conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320)\n",
       "            )\n",
       "            (convffn): ConvFFN(\n",
       "              (conv): Sequential(\n",
       "                (conv): Conv2d(320, 320, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=320, bias=False)\n",
       "                (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "              (fc1): Conv2d(320, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act): GELU(approximate='none')\n",
       "              (fc2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (23): RepMixerBlock(\n",
       "            (token_mixer): RepMixer(\n",
       "              (reparam_conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320)\n",
       "            )\n",
       "            (convffn): ConvFFN(\n",
       "              (conv): Sequential(\n",
       "                (conv): Conv2d(320, 320, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=320, bias=False)\n",
       "                (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "              (fc1): Conv2d(320, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act): GELU(approximate='none')\n",
       "              (fc2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "        )\n",
       "        (5): PatchEmbed(\n",
       "          (proj): Sequential(\n",
       "            (0): ReparamLargeKernelConv(\n",
       "              (activation): GELU(approximate='none')\n",
       "              (se): SEModule(\n",
       "                (fc1): Conv2d(640, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (bn): Identity()\n",
       "                (act): ReLU(inplace=True)\n",
       "                (fc2): Conv2d(160, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (gate): Sigmoid()\n",
       "              )\n",
       "              (lkb_reparam): Conv2d(320, 640, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), groups=320)\n",
       "            )\n",
       "            (1): MobileOneBlock(\n",
       "              (se): Identity()\n",
       "              (activation): GELU(approximate='none')\n",
       "              (reparam_conv): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (6): RepCPE(\n",
       "          (reparam_conv): Conv2d(640, 640, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=640)\n",
       "        )\n",
       "        (7): Sequential(\n",
       "          (0): AttentionBlock(\n",
       "            (norm): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (token_mixer): MHSA(\n",
       "              (qkv): Linear(in_features=640, out_features=1920, bias=False)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=640, out_features=640, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (convffn): ConvFFN(\n",
       "              (conv): Sequential(\n",
       "                (conv): Conv2d(640, 640, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=640, bias=False)\n",
       "                (bn): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "              (fc1): Conv2d(640, 1920, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act): GELU(approximate='none')\n",
       "              (fc2): Conv2d(1920, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (1): AttentionBlock(\n",
       "            (norm): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (token_mixer): MHSA(\n",
       "              (qkv): Linear(in_features=640, out_features=1920, bias=False)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=640, out_features=640, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (convffn): ConvFFN(\n",
       "              (conv): Sequential(\n",
       "                (conv): Conv2d(640, 640, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=640, bias=False)\n",
       "                (bn): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "              (fc1): Conv2d(640, 1920, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act): GELU(approximate='none')\n",
       "              (fc2): Conv2d(1920, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (2): AttentionBlock(\n",
       "            (norm): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (token_mixer): MHSA(\n",
       "              (qkv): Linear(in_features=640, out_features=1920, bias=False)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=640, out_features=640, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (convffn): ConvFFN(\n",
       "              (conv): Sequential(\n",
       "                (conv): Conv2d(640, 640, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=640, bias=False)\n",
       "                (bn): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "              (fc1): Conv2d(640, 1920, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act): GELU(approximate='none')\n",
       "              (fc2): Conv2d(1920, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (3): AttentionBlock(\n",
       "            (norm): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (token_mixer): MHSA(\n",
       "              (qkv): Linear(in_features=640, out_features=1920, bias=False)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=640, out_features=640, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (convffn): ConvFFN(\n",
       "              (conv): Sequential(\n",
       "                (conv): Conv2d(640, 640, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=640, bias=False)\n",
       "                (bn): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "              (fc1): Conv2d(640, 1920, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act): GELU(approximate='none')\n",
       "              (fc2): Conv2d(1920, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (conv_exp): MobileOneBlock(\n",
       "        (se): SEBlock(\n",
       "          (reduce): Conv2d(1280, 80, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (expand): Conv2d(80, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (activation): GELU(approximate='none')\n",
       "        (reparam_conv): Conv2d(640, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=640)\n",
       "      )\n",
       "      (head): GlobalPool2D(\n",
       "        (pool): GlobalPool()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (text_encoder): TextTransformer(\n",
       "    (embedding_layer): Embedding(49408, 512)\n",
       "    (positional_embedding): LearnablePositionalEmbedding(num_embeddings=77, embedding_dim=512, padding_idx=None)\n",
       "    (embedding_dropout): Dropout(p=0.0, inplace=False)\n",
       "    (transformer): ModuleList(\n",
       "      (0-11): 12 x TransformerEncoder(embed_dim=512, ffn_dim=2048, dropout=0.0, ffn_dropout=0.0, stochastic_dropout=0.0, attn_fn=MultiHeadAttention, act_fn=GELU, norm_fn=layer_norm_fp32)\n",
       "    )\n",
       "    (final_layer_norm): LayerNormFP32((512,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model, _, preprocess = mobileclip.create_model_and_transforms('mobileclip_s2', pretrained='/home/mobileclip_s2.pt')\n",
    "tokenizer = mobileclip.get_tokenizer('mobileclip_s2')\n",
    "# This should be called only for inference\n",
    "model = model.to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f49d1f2-b3b4-4a97-8faf-ee7fbc02d057",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ffb3bebf-acb6-41d0-8232-25bef77d4643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[49406  6323 22580 15255   530   320  3144  7437 49407     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0]\n",
      " [49406 49052 22580 15255   530   320  3144  7437 49407     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0]\n",
      " [49406  3878  2866 22580 15255   530   320  3144  7437 49407     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0]]\n"
     ]
    }
   ],
   "source": [
    "labels = ['raw', 'translucent', 'golden brown']\n",
    "texts = [ f\"{label} chopped onions in a dark pan\" for label in labels ]\n",
    "text_tokenized = tokenizer(texts).numpy()\n",
    "print(text_tokenized)\n",
    "\n",
    "def generate_txt_tokenized_given_path(img_path):\n",
    "    lbl_i = int(os.path.basename(os.path.dirname(img_path)))\n",
    "    return text_tokenized[lbl_i]\n",
    "    \n",
    "def load_data(what):\n",
    "    img_path_l = glob(os.path.join(dataset_path, what, \"*/*.jpg\"))\n",
    "    assert len(img_path_l) > 0, \"Invalid Dataset\"\n",
    "    txt_l = [ generate_txt_tokenized_given_path(img_path) for img_path in img_path_l ]\n",
    "    assert_data(img_path_l, txt_l)\n",
    "    return img_path_l, txt_l\n",
    "\n",
    "def assert_data(img_path_l, txt_l):\n",
    "    for i, (img_path, txt) in enumerate(zip(img_path_l, txt_l)):\n",
    "        assert isinstance(img_path, str) and os.path.isfile(img_path), f\"{i} {img_path} not present!\"\n",
    "        assert isinstance(txt, np.ndarray) and txt.shape == text_tokenized[0].shape\n",
    "\n",
    "train_img_path_l, train_txt_l = load_data(\"train\")\n",
    "val_img_path_l, val_txt_l = load_data(\"valid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4776050-2220-442c-8b0b-8029cea8f382",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetLoader:\n",
    "    \n",
    "    def __init__(self, img_path_l, txt_l):\n",
    "        assert len(img_path_l) == len(txt_l)\n",
    "        self.img_path_l = img_path_l\n",
    "        self.txt_l = txt_l\n",
    "        \n",
    "    def __len__(self):\n",
    "        return b_test if b_test else len(self.img_path_l)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # TODO: Add augmentation\n",
    "        image = preprocess(Image.open(self.img_path_l[idx]))\n",
    "        return image, self.txt_l[idx]\n",
    "\n",
    "train_data_loader = DataLoader(DatasetLoader(train_img_path_l, train_txt_l), batch_size=b_test if b_test else batch_size, shuffle=True)\n",
    "val_data_loader = DataLoader(DatasetLoader(val_img_path_l, val_txt_l), batch_size=b_test if b_test else batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829aff55-77e5-4405-b273-9bb559507709",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "### CLIP Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea75987c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# temperature = nn.Parameter(temperature)\n",
    "def clip_loss(img_features, txt_features):\n",
    "    img_features = img_features / img_features.norm(dim=-1, keepdim=True)\n",
    "    txt_features = txt_features / txt_features.norm(dim=-1, keepdim=True)\n",
    "    \n",
    "    logits = (img_features @ txt_features.T) * torch.exp(temperature)\n",
    "    \n",
    "    labels = torch.arange(len(logits), device=logits.device)\n",
    "    loss_i = nn.CrossEntropyLoss()(logits, labels)\n",
    "    loss_t = nn.CrossEntropyLoss()(logits.T, labels)\n",
    "    \n",
    "    return (loss_i + loss_t) / 2, logits\n",
    "\n",
    "opt = torch.optim.Adam(model.parameters(), **opt_kargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4e85e1",
   "metadata": {},
   "source": [
    "### Checkpoint save and reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08a7719d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded checkpoint /home/mobile_clip_finetuned.pth with test loss 2.2912741162184345\n"
     ]
    }
   ],
   "source": [
    "def save_checkpoint(test_loss, epoch):\n",
    "    torch.save({\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': opt.state_dict(),\n",
    "        'loss': test_loss,\n",
    "        'epoch': epoch\n",
    "    }, checkpoint_path)\n",
    "\n",
    "def load_checkpoint():\n",
    "    checkpoint = torch.load(best_checkpoint_file, weights_only=False)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    opt.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    test_loss = checkpoint['loss']\n",
    "    last_epoch = checkpoint['epoch']\n",
    "    return last_epoch, test_loss\n",
    "\n",
    "last_epoch, best_loss = 0, float('inf') # TODO: Use last_epoch this for lr decay restore\n",
    "if best_checkpoint_file:\n",
    "    last_epoch, best_loss = load_checkpoint()\n",
    "    print(f\"Loaded checkpoint {best_checkpoint_file} with test loss {best_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbfdbf5f",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54f6b855-40c7-40e5-b487-20b25dc06010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 346/346 [04:40<00:00,  1.24it/s, Loss: 2.3259]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss 2.3259\n",
      "\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|█▉        | 66/346 [00:53<03:46,  1.23it/s, Loss: 2.3097]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m     16\u001b[0m running_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m img, txt \u001b[38;5;129;01min\u001b[39;00m pbar:\n\u001b[1;32m     18\u001b[0m     opt\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     19\u001b[0m     img \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m/root/miniconda3/envs/py3.10/lib/python3.10/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1183\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1184\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m/root/miniconda3/envs/py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/root/miniconda3/envs/py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py:673\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    671\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    672\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 673\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    674\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    675\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/root/miniconda3/envs/py3.10/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/root/miniconda3/envs/py3.10/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[0;32mIn[7], line 13\u001b[0m, in \u001b[0;36mDatasetLoader.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;66;03m# TODO: Add augmentation\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimg_path_l\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m image, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtxt_l[idx]\n",
      "File \u001b[0;32m/root/miniconda3/envs/py3.10/lib/python3.10/site-packages/torchvision/transforms/transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[0;32m---> 95\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[0;32m/root/miniconda3/envs/py3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/root/miniconda3/envs/py3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/root/miniconda3/envs/py3.10/lib/python3.10/site-packages/torchvision/transforms/transforms.py:354\u001b[0m, in \u001b[0;36mResize.forward\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[1;32m    347\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    349\u001b[0m \u001b[38;5;124;03m        img (PIL Image or Tensor): Image to be scaled.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;124;03m        PIL Image or Tensor: Rescaled image.\u001b[39;00m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 354\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpolation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mantialias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/root/miniconda3/envs/py3.10/lib/python3.10/site-packages/torchvision/transforms/functional.py:477\u001b[0m, in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation, max_size, antialias)\u001b[0m\n\u001b[1;32m    475\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnti-alias option is always applied for PIL Image input. Argument antialias is ignored.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    476\u001b[0m     pil_interpolation \u001b[38;5;241m=\u001b[39m pil_modes_mapping[interpolation]\n\u001b[0;32m--> 477\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF_pil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpil_interpolation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m F_t\u001b[38;5;241m.\u001b[39mresize(img, size\u001b[38;5;241m=\u001b[39moutput_size, interpolation\u001b[38;5;241m=\u001b[39minterpolation\u001b[38;5;241m.\u001b[39mvalue, antialias\u001b[38;5;241m=\u001b[39mantialias)\n",
      "File \u001b[0;32m/root/miniconda3/envs/py3.10/lib/python3.10/site-packages/torchvision/transforms/_functional_pil.py:250\u001b[0m, in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(size, \u001b[38;5;28mlist\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(size) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m):\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot inappropriate size arg: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msize\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 250\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/root/miniconda3/envs/py3.10/lib/python3.10/site-packages/PIL/Image.py:2293\u001b[0m, in \u001b[0;36mImage.resize\u001b[0;34m(self, size, resample, box, reducing_gap)\u001b[0m\n\u001b[1;32m   2290\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreducing_gap must be 1.0 or greater\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2291\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m-> 2293\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m box \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2295\u001b[0m     box \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize\n",
      "File \u001b[0;32m/root/miniconda3/envs/py3.10/lib/python3.10/site-packages/PIL/ImageFile.py:293\u001b[0m, in \u001b[0;36mImageFile.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    290\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(msg)\n\u001b[1;32m    292\u001b[0m b \u001b[38;5;241m=\u001b[39m b \u001b[38;5;241m+\u001b[39m s\n\u001b[0;32m--> 293\u001b[0m n, err_code \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    295\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if tensorboard:\n",
    "    writer = SummaryWriter(log_dir=f\"tb_logs/{datetime.now().strftime('%d%m%y_%H%M%S')}\")\n",
    "    \n",
    "def tb_log_scaler(what, val, step):\n",
    "    if tensorboard:\n",
    "        writer.add_scalar(what, val, global_step=step)\n",
    "\n",
    "# Train loop\n",
    "train_step, val_step = 0, 0\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    print(f\"\\nEpoch {epoch}/{num_epochs}\")\n",
    "\n",
    "    # Training\n",
    "    pbar = tqdm(train_data_loader, total=b_test if b_test else len(train_data_loader), desc=\"Training\", ncols=100)\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for img, txt in pbar:\n",
    "        opt.zero_grad()\n",
    "        img = img.to(device)\n",
    "        txt = txt.to(device)\n",
    "        \n",
    "        # forward\n",
    "        img_features = model.encode_image(img)\n",
    "        txt_features = model.encode_text(txt)\n",
    "\n",
    "        \n",
    "        if lit_mode:\n",
    "            img_features = img_features.detach()\n",
    "        # loss\n",
    "        loss, logits = clip_loss(img_features, txt_features)\n",
    "        assert logits.size(0) == img.size(0)\n",
    "        \n",
    "        tb_log_scaler(\"train/loss_step\", loss.item(), train_step)\n",
    "        train_step += 1\n",
    "\n",
    "        # backward\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        running_loss += loss.item() \n",
    "        # running_loss / (batch_idx + 1)\n",
    "\n",
    "        pbar.set_postfix_str(f\"Loss: {running_loss / (pbar.n + 1):.4f}\")\n",
    "    train_loss = running_loss / len(train_data_loader)\n",
    "    print(f'Training Loss {train_loss:.4f}')\n",
    "    tb_log_scaler(\"train/loss_epoch\", train_loss, epoch)    \n",
    "\n",
    "    # # Validation\n",
    "    # model.eval()\n",
    "    # running_loss = 0\n",
    "    # correct, total = 0, 0\n",
    "    # with torch.no_grad():\n",
    "        \n",
    "    #     pbar = tqdm(val_data_loader, total=b_test if b_test else len(val_data_loader), desc=\"Testing \", ncols=100)\n",
    "    #     for img, txt in pbar:\n",
    "    #         img = img.to(device)\n",
    "    #         txt = txt.to(device)\n",
    "\n",
    "    #         img_features = model.encode_image(img)\n",
    "    #         txt_features = model.encode_text(txt)\n",
    "\n",
    "    #         loss, logits = clip_loss(img_features, txt_features)\n",
    "    #         assert logits.size(0) == img.size(0)\n",
    "    #         tb_log_scaler(\"val/loss_step\", loss.item(), val_step)\n",
    "    #         val_step += 1\n",
    "\n",
    "    #         lbl_hat = torch.argmax(logits, axis=1)\n",
    "    #         lbl = torch.arange(len(lbl_hat), device=lbl_hat.device)\n",
    "\n",
    "    #         correct += (lbl_hat == lbl).sum().cpu().item() \n",
    "    #         total += logits.size(0)\n",
    "\n",
    "    #         running_loss += loss.item()\n",
    "    #         pbar.set_postfix_str(f\"Validation Loss: {running_loss / (pbar.n + 1):.4f} Accuracy: {correct / total:.2%}\")\n",
    "    # test_loss = running_loss / len(val_data_loader)\n",
    "    # test_acc = correct / total\n",
    "    # print(f\"Test Loss:{test_loss:.4f} Test Acc:{test_acc:.2%}\")\n",
    "    # tb_log_scaler(\"val/loss_epoch\", test_loss, epoch)\n",
    "    # tb_log_scaler(\"val/accuracy\", correct / total, epoch)\n",
    "    if train_loss < best_loss:\n",
    "        best_loss = train_loss\n",
    "        save_checkpoint(best_loss, epoch)\n",
    "        print(f\"Saved checkpoint to {checkpoint_path} with Loss: {best_loss}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
